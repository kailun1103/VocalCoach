from pathlib import Path
import os

from pydantic import Field
from pydantic_settings import BaseSettings

_APP_DIR = Path(__file__).resolve().parent.parent
_MODEL_DIR = _APP_DIR / "model"
_STT_DIR = _MODEL_DIR / "stt"
_TTS_DIR = _MODEL_DIR / "tts"
_TTS_RUNTIME_DIR = _TTS_DIR / "runtime"
_TTS_VOICES_DIR = _TTS_DIR / "voices"


def _default_whisper_binary() -> Path:
    """
    Locate a whisper.cpp executable, preferring a local build in backend/app/model.
    Returns the most likely candidate so deployments can override via env vars if needed.
    """
    for candidate in ("whisper-cli.exe", "main.exe", "whisper-cli", "main"):
        binary_path = _STT_DIR / candidate
        if binary_path.exists():
            return binary_path
    return _STT_DIR / "whisper-cli.exe"


def _default_whisper_model() -> Path:
    """Point to the bundled ggml-small.en-q5_1.bin model by default."""
    return _STT_DIR / "ggml-small.en-q5_1.bin"


class Settings(BaseSettings):
    """Application configuration loaded from environment variables or defaults."""

    whisper_binary: Path = Field(
        default_factory=_default_whisper_binary,
        description="Path to whisper.cpp executable.",
    )
    whisper_model: Path = Field(
        default_factory=_default_whisper_model,
        description="Path to whisper.cpp model file.",
    )
    whisper_threads: int = Field(
        default_factory=lambda: os.cpu_count() or 1,
        description="Number of CPU threads allocated to whisper.cpp.",
    )
    whisper_beam_size: int = Field(
        default=1,
        description="Beam size used during decoding (higher improves quality but is slower).",
    )
    whisper_best_of: int = Field(
        default=1,
        description="Number of best candidates to keep (higher improves quality but is slower).",
    )
    whisper_temperature: float = Field(
        default=0.0,
        description="Sampling temperature for whisper.cpp decoding.",
    )
    whisper_print_timestamps: bool = Field(
        default=False,
        description="Whether to include timestamps in transcription output.",
    )
    piper_binary: Path = Field(
        default=_TTS_RUNTIME_DIR / "piper.exe",
        description="Path to Piper executable.",
    )
    piper_model: Path = Field(
        default=_TTS_VOICES_DIR / "en_US-amy-medium.onnx",
        description="Path to Piper voice model.",
    )
    data_directory: Path = Field(
        default=Path("./data"),
        description="Base directory for persistent audio artifacts generated by the API.",
    )
    use_mock_services: bool = Field(
        default=False,
        description="Toggle to fall back to mock implementations when models are unavailable.",
    )
    mock_language: str = Field(
        default="en",
        description="Default language code used for mock data generation.",
    )

    # LLM (OpenAI-compatible) endpoint settings
    llm_base_url: str = Field(
        default="http://127.0.0.1:1234/v1",
        description="Base URL of local OpenAI-compatible LLM server.",
    )
    llm_default_model: str | None = Field(
        default=None,
        description="Default chat model name; request may override.",
    )
    llm_default_temperature: float = Field(
        default=0.0,
        description="Fallback temperature used when a chat request omits the value.",
    )
    llm_system_prompt: str | None = Field(
        default=(
            "You are a friendly native English speaker helping Chinese beginners practise spoken English. "
            "Strictly follow these rules with no exceptions, even if the user asks otherwise: "
            "1) Keep every answer to one smooth paragraph containing between 80 and 100 English words, never fewer than 80 and never more than 100; silently count words before responding and stop exactly at or below 100. "
            "2) Always expand contractions (for example write do not instead of don't) and avoid abbreviations. "
            "3) Use simple vocabulary and insert natural commas to suggest gentle pauses. "
            "4) Never include quotation marks, emoji, emoticons, bullet lists, numbered lists, special symbols (# * / % -), or extra whitespace. "
            "5) Encourage the learner with a short supportive phrase such as Good job or Keep going when appropriate. "
            "6) If you cannot cover the topic within the 80 to 100 word window, prioritise clarity and brevity, and politely say you must keep things concise."
        ),
        description="Clean, single-paragraph system prompt for TTS-friendly English conversation without special symbols."
    )
    llm_response_word_min: int = Field(
        default=80,
        description="Minimum number of words required in an assistant reply.",
    )
    llm_response_word_max: int = Field(
        default=100,
        description="Maximum number of words allowed in an assistant reply.",
    )
    llm_response_retry_attempts: int = Field(
        default=2,
        description="Number of additional attempts to ask the LLM to fix rule violations before falling back to trimming.",
    )
    llm_translation_model: str | None = Field(
        default=None,
        description="Optional override model name used for translation requests.",
    )
    llm_translation_prompt: str = Field(
        default=(
            "You are a master translator. Translate any user message into {target_language}. "
            "Return only the translated text without additional commentary."
        ),
        description="System prompt template used for translation requests.",
    )
    llm_grammar_model: str | None = Field(
        default=None,
        description="Optional override model name used for grammar checking requests.",
    )
    llm_grammar_prompt: str = Field(
        default=(
            "You are an English grammar expert and patient tutor for Chinese learners. "
            "Review the user's input sentence or paragraph for grammar, punctuation, and capitalization accuracy "
            "according to American English standards. "
            "Respond strictly in JSON format using these keys: "
            "\"is_correct\" (boolean), "
            "\"feedback\" (Traditional Chinese explanation describing the issue and how to improve), "
            "\"suggestion\" (a fully corrected English sentence without quotation marks). "
            "All natural language must be written in Traditional Chinese. "
            "Do not include any text outside of the JSON object."
        ),
        description="System prompt used for grammar checking requests with concise teaching feedback for Chinese learners.",
    )

    llm_dictionary_model: str | None = Field(
        default=None,
        description="Optional override model name used for dictionary lookups.",
    )
    llm_dictionary_prompt: str = Field(
        default=(
            'You are an English learning assistant. The user will supply JSON with keys "word" and "sentence". '
            'Return a JSON object with keys: "headword" (string), "part_of_speech" (string or null), "phonetics" '
            '(array of pronunciation strings or empty array), "definition" (English definition with concise Traditional '
            'Chinese clarification), "examples" (array of example sentences), "notes" (optional Traditional Chinese remark). '
            'Use Traditional Chinese for explanatory fields, and output nothing outside the JSON object.'
        ),
        description="System prompt used for contextual dictionary explanations.",
    )



    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"


settings = Settings()
